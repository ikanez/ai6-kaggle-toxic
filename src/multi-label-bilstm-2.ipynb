{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Based on github code at:\n",
    "https://raw.githubusercontent.com/keitakurita/practical-torchtext/master/Lesson%201%20intro%20to%20torchtext%20with%20text%20classification.ipynb\n",
    "\n",
    "### For more (like really detailed) readup, check out the author's blog at:\n",
    "http://mlexplained.com/2018/02/08/a-comprehensive-tutorial-to-torchtext/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train and validation set\n",
    "ori_train = pd.read_csv(\"C://Users/hafid/Dropbox/3.SelfStudy/kaggle/ai6-kaggle-toxic/data/train/train.csv\").values\n",
    "\n",
    "# load test set\n",
    "test_df = pd.read_csv(\"C://Users/hafid/Dropbox/3.SelfStudy/kaggle/ai6-kaggle-toxic/data/test/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dependent variable and independent variable\n",
    "y=ori_train[:,2:]\n",
    "x=ori_train[:,0:2]\n",
    "\n",
    "# split training set and testing set\n",
    "from sklearn.cross_validation import train_test_split\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn into dataframes\n",
    "new_train = np.concatenate((xtrain, ytrain), axis=1)\n",
    "new_valid = np.concatenate((xtest, ytest), axis=1)\n",
    "\n",
    "train_df = pd.DataFrame(new_train,columns=[\"id\",\"comment_text\",\"toxic\",\"severe_toxic\",\"obscene\",\"threat\",\"insult\",\"identity_hate\"])\n",
    "valid_df = pd.DataFrame(new_valid, columns=[\"id\",\"comment_text\",\"toxic\",\"severe_toxic\",\"obscene\",\"threat\",\"insult\",\"identity_hate\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a bit of massaging to remove newlines\n",
    "train_df['comment_text'] = train_df['comment_text'].str.replace('\\n',' ')\n",
    "valid_df['comment_text'] = valid_df['comment_text'].str.replace('\\n',' ')\n",
    "test_df['comment_text'] = test_df['comment_text'].str.replace('\\n',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we'll export these out to keita_data folder since traditionally torchtext loads data via csv, not dataframes\n",
    "train_df.to_csv(\"C://Users/hafid/Dropbox/3.SelfStudy/kaggle/ai6-kaggle-toxic/data/keita_data/train.csv\", index = False)\n",
    "valid_df.to_csv(\"C://Users/hafid/Dropbox/3.SelfStudy/kaggle/ai6-kaggle-toxic/data/keita_data/valid.csv\", index = False)\n",
    "test_df.to_csv(\"C://Users/hafid/Dropbox/3.SelfStudy/kaggle/ai6-kaggle-toxic/data/keita_data/test.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's examine what the data looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0bc240e647fd49e7</td>\n",
       "      <td>That's your POV talking, which isn't really re...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c75a1622fe2d21ae</td>\n",
       "      <td>Obviously long term population predictions are...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>f664d0a69b9d5f33</td>\n",
       "      <td>I have limited experience with this guy, but t...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>92dbcf851942462f</td>\n",
       "      <td>\" Again, RCOO-M+ is archaic.  Please read my r...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f096887295b234f3</td>\n",
       "      <td>FYI: Please see this: User talk:Central. If th...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>57b5093689ca3fe8</td>\n",
       "      <td>\" We know she was charged with shooting at the...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6d0ef1f2fe1a34db</td>\n",
       "      <td>It occurred to me that I regard the EU as inde...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>512782c73bf30b53</td>\n",
       "      <td>If you want to file a report go ahead, just be...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ec2072c145eb2546</td>\n",
       "      <td>HTML Coding Damaged @ Bottom   The tables near...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>a3a8d4b22acaa208</td>\n",
       "      <td>\"      Hi Wally, not sure if you are picking t...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0bc240e647fd49e7  That's your POV talking, which isn't really re...      0   \n",
       "1  c75a1622fe2d21ae  Obviously long term population predictions are...      0   \n",
       "2  f664d0a69b9d5f33  I have limited experience with this guy, but t...      0   \n",
       "3  92dbcf851942462f  \" Again, RCOO-M+ is archaic.  Please read my r...      0   \n",
       "4  f096887295b234f3  FYI: Please see this: User talk:Central. If th...      0   \n",
       "5  57b5093689ca3fe8  \" We know she was charged with shooting at the...      0   \n",
       "6  6d0ef1f2fe1a34db  It occurred to me that I regard the EU as inde...      0   \n",
       "7  512782c73bf30b53  If you want to file a report go ahead, just be...      0   \n",
       "8  ec2072c145eb2546  HTML Coding Damaged @ Bottom   The tables near...      0   \n",
       "9  a3a8d4b22acaa208  \"      Hi Wally, not sure if you are picking t...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  \n",
       "5             0        0       0       0              0  \n",
       "6             0        0       0       0              0  \n",
       "7             0        0       0       0              0  \n",
       "8             0        0       0       0              0  \n",
       "9             0        0       0       0              0  "
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"C://Users/hafid/Dropbox/3.SelfStudy/kaggle/ai6-kaggle-toxic/data/keita_data/train.csv\").head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apparently we have to predict 6 labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>Yo bitch Ja Rule is more succesful then you'll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>== From RfC ==    The title is fine as it is, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>\"    == Sources ==    * Zawe Ashton on Lapland...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>:If you have a look back at the source, the in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>I don't anonymously edit articles at all.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0001ea8717f6de06</td>\n",
       "      <td>Thank you for understanding. I think very high...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>00024115d4cbde0f</td>\n",
       "      <td>Please do not add nonsense to Wikipedia. Such ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>000247e83dcc1211</td>\n",
       "      <td>:Dear god this site is horrible.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00025358d4737918</td>\n",
       "      <td>\"   Only a fool can believe in such numbers.  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>00026d1092fe71cc</td>\n",
       "      <td>== Double Redirects ==    When fixing double r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text\n",
       "0  00001cee341fdb12  Yo bitch Ja Rule is more succesful then you'll...\n",
       "1  0000247867823ef7  == From RfC ==    The title is fine as it is, ...\n",
       "2  00013b17ad220c46  \"    == Sources ==    * Zawe Ashton on Lapland...\n",
       "3  00017563c3f7919a  :If you have a look back at the source, the in...\n",
       "4  00017695ad8997eb          I don't anonymously edit articles at all.\n",
       "5  0001ea8717f6de06  Thank you for understanding. I think very high...\n",
       "6  00024115d4cbde0f  Please do not add nonsense to Wikipedia. Such ...\n",
       "7  000247e83dcc1211                   :Dear god this site is horrible.\n",
       "8  00025358d4737918  \"   Only a fool can believe in such numbers.  ...\n",
       "9  00026d1092fe71cc  == Double Redirects ==    When fixing double r..."
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"C://Users/hafid/Dropbox/3.SelfStudy/kaggle/ai6-kaggle-toxic/data/keita_data/test.csv\").head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declaring Fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Field class determines how the data is preprocessed and converted into a numeric format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import Field"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want comment_text field to be converted to lowercase, tokenized on whitespace, and preprocessed. So we tell that to the Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize = lambda x: x.split()\n",
    "TEXT = Field(sequential=True, tokenize=tokenize, lower=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That was simple. The preprocessing of the labels is even easier, since they are already converted into a binary encoding.\n",
    "All we need to do is to tell the Field class that the labels are already processed. We do this by passing the use_vocab=False keyword to the constructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL = Field(sequential=False, use_vocab=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use the TabularDataset class to read our data, since it is in csv format (TabularDataset handles csv, tsv, and json files as of now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import TabularDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the train and validation data, we need to process the labels. The fields we pass in must be in the same order as the columns. For fields we don't use, we pass in a tuple where the second element is None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"C://Users/hafid/Dropbox/3.SelfStudy/kaggle/ai6-kaggle-toxic/data/keita_data/\"\n",
    "TRAIN_FN = \"train.csv\"\n",
    "VALID_FN = \"valid.csv\"\n",
    "TEST_FN = \"test.csv\"\n",
    "TEST_PATH = PATH + TEST_FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C://Users/hafid/Dropbox/3.SelfStudy/kaggle/ai6-kaggle-toxic/data/keita_data/test.csv'"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEST_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6.31 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tv_datafields = [(\"id\", None), # we won't be needing the id, so we pass in None as the field\n",
    "                 (\"comment_text\", TEXT), (\"toxic\", LABEL),\n",
    "                 (\"severe_toxic\", LABEL), (\"threat\", LABEL),\n",
    "                 (\"obscene\", LABEL), (\"insult\", LABEL),\n",
    "                 (\"identity_hate\", LABEL)]\n",
    "\n",
    "trn, vld = TabularDataset.splits(\n",
    "        path=PATH, # the root directory where the data lies\n",
    "        train=TRAIN_FN, validation=VALID_FN,\n",
    "        format='csv',\n",
    "        skip_header=True, # if your csv header has a header, make sure to pass this to ensure it doesn't get proceesed as data!\n",
    "        fields=tv_datafields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('id', None),\n",
       " ('comment_text', <torchtext.data.field.Field at 0x1814508d208>),\n",
       " ('toxic', <torchtext.data.field.Field at 0x1814508d198>),\n",
       " ('severe_toxic', <torchtext.data.field.Field at 0x1814508d198>),\n",
       " ('threat', <torchtext.data.field.Field at 0x1814508d198>),\n",
       " ('obscene', <torchtext.data.field.Field at 0x1814508d198>),\n",
       " ('insult', <torchtext.data.field.Field at 0x1814508d198>),\n",
       " ('identity_hate', <torchtext.data.field.Field at 0x1814508d198>)]"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tv_datafields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the test data, we don't have any labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6.13 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tst_datafields = [(\"id\", None), # we won't be needing the id, so we pass in None as the field\n",
    "                 (\"comment_text\", TEXT)\n",
    "]\n",
    "\n",
    "tst = TabularDataset(\n",
    "        path=TEST_PATH, # the file path\n",
    "        format='csv',\n",
    "        skip_header=True, # if your csv header has a header, make sure to pass this to ensure it doesn't get proceesed as data!\n",
    "        fields=tst_datafields)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the TEXT field to convert words into integers, it needs to be told what the entire vocabulary is. To do this, we run TEXT.build_vocab, passing in the dataset to build the vocabulary on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.62 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "TEXT.build_vocab(trn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at what the vocab looks like.\n",
    "\n",
    "The vocab.freqs is a collections.Counter object, so we can take a look at the most frequent words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 368752),\n",
       " ('to', 220799),\n",
       " ('of', 167202),\n",
       " ('and', 163975),\n",
       " ('a', 159533),\n",
       " ('i', 148251),\n",
       " ('you', 139392),\n",
       " ('is', 128545),\n",
       " ('that', 110350),\n",
       " ('in', 105814)]"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab.freqs.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also instructive to take a look inside the Dataset. Datasets can be indexed like normal lists, so we'll look at the first element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torchtext.data.example.Example at 0x18146776860>"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each element of the dataset is an Example object that bundles the attributes of a single data point together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['comment_text', 'toxic', 'severe_toxic', 'threat', 'obscene', 'insult', 'identity_hate'])"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn[0].__dict__.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the comment text is already tokenized for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"that's\", 'your', 'pov']"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn[0].comment_text[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking good. Now, let's build the Iterator which will allow us to load the data into our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import Iterator, BucketIterator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During training, we'll be using a special kind of Iterator, called the **BucketIterator**.\n",
    "\n",
    "When we pass data into a neural network, we want the data to be padded to be the same length so that we can process them in batch:\n",
    "\n",
    "e.g.\n",
    "\\[ \n",
    "\\[3, 15, 2, 7\\],\n",
    "\\[4, 1\\], \n",
    "\\[5, 5, 6, 8, 1\\] \n",
    "\\] -> \\[ \n",
    "\\[3, 15, 2, 7, **0**\\],\n",
    "\\[4, 1, **0**, **0**, **0**\\], \n",
    "\\[5, 5, 6, 8, 1\\] \n",
    "\\] \n",
    "\n",
    "If the sequences differ greatly in length, the padding will consume a lot of wasteful memory and time.\n",
    "\n",
    "The BucketIterator groups sequences of similar lengths together for each batch to minimize padding. Handy, right?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter, val_iter = BucketIterator.splits(\n",
    "        (trn, vld), # we pass in the datasets we want the iterator to draw data from\n",
    "        batch_sizes=(64, 64),\n",
    "        device=0, # if you want to use the GPU, specify the GPU number here\n",
    "        sort_key=lambda x: len(x.comment_text), # the BucketIterator needs to be told what function it should use to group the data.\n",
    "        sort_within_batch=False,\n",
    "        repeat=False # we pass repeat=False because we want to wrap this Iterator layer.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at what the output of the BucketIterator looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torchtext.data.batch.Batch at 0x18145202550>"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(train_iter.__iter__()); batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The batch has all the fields we passed to the Dataset as attributes. The batch data can be accessed through the attribute with the same name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['batch_size', 'dataset', 'train', 'comment_text', 'toxic', 'severe_toxic', 'threat', 'obscene', 'insult', 'identity_hate'])"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.__dict__.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the test set, we don't want the data to be shuffled. This is why we'll be using a standard Iterator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_iter = Iterator(tst, batch_size=64, device=0, train=False, sort=False, sort_within_batch=False, repeat=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrapping the Iterator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently, the iterator returns a custom datatype called torchtext.data.Batch. This makes code reuse difficult (since each time the column names change, we need to modify the code), and makes torchtext hard to use with other libraries for some use cases (like torchsample and fastai). \n",
    "\n",
    "I hope this will be dealt with in the future (I'm considering filing a PR if I can decide what the API should look like), but in the meantime, we'll hack on a simple wrapper to make the batches easy to use. \n",
    "\n",
    "Concretely, we'll convert the batch to a tuple in the form (x, y) where x is the independent variable (the input to the model) and y is the dependent variable (the supervision data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchWrapper:\n",
    "    def __init__(self, dl, x_var, y_vars):\n",
    "        self.dl, self.x_var, self.y_vars = dl, x_var, y_vars # we pass in the list of attributes for x and y\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for batch in self.dl:\n",
    "            x = getattr(batch, self.x_var) # we assume only one input in this wrapper\n",
    "            \n",
    "            if self.y_vars is not None: # we will concatenate y into a single tensor\n",
    "                y = torch.cat([getattr(batch, feat).unsqueeze(1) for feat in self.y_vars], dim=1).float()\n",
    "            else:\n",
    "                y = torch.zeros((1))\n",
    "\n",
    "            yield (x, y)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use this to wrap the BucketIterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = BatchWrapper(train_iter, \"comment_text\", [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"])\n",
    "valid_dl = BatchWrapper(val_iter, \"comment_text\", [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"])\n",
    "test_dl = BatchWrapper(test_iter, \"comment_text\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Variable containing:\n",
       " \n",
       " Columns 0 to 5 \n",
       "  3.5585e+05  7.3000e+01  4.9970e+04  1.8400e+02  1.2501e+05  4.7290e+03\n",
       "  2.5000e+01  1.5000e+01  4.7697e+04  5.0000e+00  8.0000e+00  4.8000e+01\n",
       "  2.5458e+04  1.0600e+03  5.1580e+03  6.0000e+00  2.3720e+03  2.3061e+05\n",
       "  1.5300e+02  5.1000e+01  1.5200e+02  6.2170e+03  6.4970e+03  4.8000e+01\n",
       "  6.0000e+00  1.2300e+02  1.6000e+01  2.5100e+02  8.0000e+00  3.0000e+00\n",
       "  8.3910e+03  9.0000e+00  2.0000e+00  1.1000e+01  9.3000e+01  5.8760e+03\n",
       "  1.5742e+05  6.0000e+00  1.0666e+04  6.6000e+01  4.9000e+01  1.6000e+01\n",
       "  2.7400e+02  5.1500e+03  4.7417e+04  7.2220e+03  1.2246e+04  3.4121e+05\n",
       "  1.0000e+00  1.0000e+00  1.0000e+00  1.0000e+00  1.0000e+00  1.0000e+00\n",
       " \n",
       " Columns 6 to 11 \n",
       "  6.9000e+01  4.9700e+02  1.7174e+04  2.3787e+05  7.3500e+02  3.6567e+05\n",
       "  2.0000e+00  3.0000e+00  7.7000e+01  7.6000e+01  2.8034e+05  8.0000e+00\n",
       "  8.7000e+02  5.1000e+02  2.9600e+02  3.4000e+01  2.0564e+05  9.2200e+02\n",
       "  8.8696e+04  4.0000e+00  8.0000e+00  8.0000e+00  2.5000e+01  2.0000e+00\n",
       "  8.1000e+01  1.6260e+03  2.0000e+01  2.9100e+02  1.0360e+03  7.6230e+03\n",
       "  4.7000e+01  3.0000e+00  6.0000e+00  8.4150e+03  2.3000e+01  2.6470e+03\n",
       "  3.8000e+01  2.0000e+00  3.7060e+03  2.8844e+05  7.2680e+03  4.2000e+01\n",
       "  5.5390e+03  6.0608e+04  1.0863e+04  6.7238e+04  3.3791e+05  3.1980e+03\n",
       "  1.0000e+00  1.0000e+00  1.0000e+00  1.0000e+00  1.0000e+00  1.0000e+00\n",
       " \n",
       " Columns 12 to 17 \n",
       "  9.0000e+00  2.5230e+03  2.8800e+02  1.2000e+01  2.9590e+03  7.9254e+04\n",
       "  3.1800e+02  2.0700e+02  1.6570e+03  8.6080e+03  1.0700e+02  5.5000e+01\n",
       "  2.3213e+05  1.3800e+02  2.3000e+01  1.6000e+01  1.5000e+01  2.5884e+04\n",
       "  7.0000e+00  6.0000e+00  6.6000e+01  7.4070e+03  2.0000e+00  1.3352e+04\n",
       "  2.0100e+02  4.9150e+03  2.4952e+05  5.0000e+00  8.8540e+03  5.5000e+01\n",
       "  1.4100e+02  2.7400e+02  1.8211e+05  2.0000e+00  3.0000e+00  5.0000e+01\n",
       "  9.9290e+03  3.6310e+03  5.2880e+03  1.3898e+04  8.5000e+01  1.4974e+04\n",
       "  1.9100e+02  6.6615e+04  1.0863e+04  3.2240e+03  2.1760e+03  1.9220e+03\n",
       "  1.0000e+00  1.0000e+00  1.0000e+00  1.0000e+00  1.0000e+00  1.0000e+00\n",
       " \n",
       " Columns 18 to 23 \n",
       "  2.2344e+04  2.6600e+02  5.5200e+02  3.2840e+03  7.0100e+02  8.0000e+00\n",
       "  7.2000e+01  3.4132e+05  5.6000e+01  6.0200e+02  3.4000e+02  9.3900e+02\n",
       "  1.9500e+02  2.9400e+02  2.5400e+02  8.0000e+00  8.0000e+00  7.0000e+00\n",
       "  7.5700e+02  2.7180e+03  9.4930e+03  2.9010e+03  6.0000e+00  2.0800e+02\n",
       "  3.4000e+01  9.2000e+01  4.8700e+02  1.4190e+03  1.5490e+03  1.2000e+02\n",
       "  6.0000e+00  2.8300e+03  2.6990e+03  6.9800e+02  7.2900e+02  5.3000e+01\n",
       "  1.0450e+03  6.1000e+02  3.1800e+02  2.1860e+03  4.0000e+00  1.5348e+04\n",
       "  3.9910e+03  2.7400e+02  8.4618e+04  2.6447e+04  1.2485e+05  4.6040e+03\n",
       "  1.0000e+00  1.0000e+00  1.0000e+00  1.0000e+00  1.0000e+00  1.0000e+00\n",
       " \n",
       " Columns 24 to 29 \n",
       "  5.0000e+01  7.0000e+00  5.9070e+03  1.8000e+01  1.1000e+02  9.0000e+00\n",
       "  9.1800e+02  2.9100e+02  6.0000e+01  4.0800e+02  1.3500e+02  1.2000e+01\n",
       "  2.5700e+02  1.5500e+02  6.7400e+02  1.4000e+01  3.6800e+02  9.2490e+03\n",
       "  1.1100e+02  7.0000e+00  1.0200e+02  2.9750e+03  8.0000e+00  3.0000e+00\n",
       "  1.1000e+02  2.9100e+02  6.0000e+00  1.0000e+01  2.3720e+03  6.3000e+02\n",
       "  4.8800e+02  1.5500e+02  1.2344e+05  1.2000e+01  7.4860e+03  6.0000e+00\n",
       "  2.2000e+01  7.0000e+00  4.2930e+03  1.4610e+04  1.3795e+04  2.7380e+03\n",
       "  2.1277e+04  2.9100e+02  5.0000e+00  2.0761e+04  4.0000e+00  1.6100e+02\n",
       "  1.1841e+04  4.9600e+02  3.5868e+05  1.8000e+01  2.1822e+04  6.4812e+04\n",
       " \n",
       " Columns 30 to 35 \n",
       "  1.2000e+01  1.8000e+01  1.3700e+02  1.0000e+01  7.2000e+01  8.0000e+00\n",
       "  2.5000e+01  2.8000e+02  3.6044e+05  1.7800e+02  1.5000e+01  2.0000e+01\n",
       "  1.5000e+01  1.8670e+03  7.1000e+01  1.7300e+02  1.9500e+02  4.5700e+02\n",
       "  6.8820e+03  9.5400e+02  3.5000e+01  1.9700e+03  7.1000e+01  6.0000e+00\n",
       "  1.2000e+01  2.2000e+02  2.6900e+02  1.0000e+01  3.0000e+00  4.3400e+02\n",
       "  2.5000e+01  1.7400e+02  3.6044e+05  4.6000e+01  1.5770e+03  8.0000e+00\n",
       "  1.3410e+03  3.0000e+01  3.0000e+00  7.1800e+02  2.0000e+00  2.0800e+02\n",
       "  6.0000e+00  1.6942e+05  2.0000e+00  1.7000e+01  4.2000e+01  8.3430e+03\n",
       "  1.6500e+03  1.8000e+01  7.1920e+03  3.3580e+03  4.8470e+03  9.3800e+02\n",
       " \n",
       " Columns 36 to 41 \n",
       "  2.2000e+01  4.5900e+02  2.4140e+03  1.8000e+01  4.5640e+03  3.3230e+03\n",
       "  4.4900e+02  3.5042e+05  2.0000e+00  7.1000e+01  7.0000e+00  1.7404e+05\n",
       "  1.5400e+02  4.0000e+00  3.8200e+02  3.5000e+01  7.1800e+02  2.7448e+04\n",
       "  1.7066e+04  2.0000e+00  4.0000e+00  2.0000e+00  1.7000e+01  9.5000e+02\n",
       "  4.0000e+00  1.4060e+03  2.0000e+00  5.6113e+04  1.8200e+02  6.2100e+02\n",
       "  1.2840e+03  6.6560e+03  1.0900e+03  1.4072e+05  4.7000e+01  2.5080e+03\n",
       "  1.1860e+03  1.3000e+01  1.2850e+03  1.8838e+05  1.3000e+01  9.3200e+02\n",
       "  9.2900e+02  1.0866e+04  5.0000e+00  3.1000e+01  8.7000e+01  2.3660e+03\n",
       "  9.4609e+04  1.7336e+05  9.0000e+00  3.6930e+05  4.7275e+04  1.8800e+02\n",
       " \n",
       " Columns 42 to 47 \n",
       "  2.7970e+03  5.2800e+02  2.2579e+04  2.1000e+01  3.5991e+05  9.1770e+03\n",
       "  4.2054e+04  1.8400e+02  7.1000e+01  4.5006e+04  5.5000e+01  4.2000e+01\n",
       "  1.3500e+02  5.8100e+02  9.0000e+00  2.7860e+03  3.5739e+05  1.4000e+01\n",
       "  1.2291e+04  2.2000e+01  1.1300e+02  2.6000e+01  3.2000e+01  8.5000e+02\n",
       "  3.1138e+04  1.6100e+02  5.1000e+01  4.1000e+01  6.3770e+03  2.0380e+03\n",
       "  9.0000e+00  4.8882e+04  3.3340e+03  4.5200e+02  5.5000e+01  4.8000e+01\n",
       "  6.0000e+00  6.0550e+03  6.6000e+01  1.0600e+02  1.3438e+04  6.0000e+00\n",
       "  1.1360e+03  4.1000e+01  2.6950e+03  1.7000e+01  3.2000e+01  9.1770e+03\n",
       "  5.8360e+04  2.0926e+04  3.2524e+05  9.7540e+03  1.0540e+04  1.2100e+02\n",
       " \n",
       " Columns 48 to 53 \n",
       "  1.7830e+04  6.3900e+02  1.0500e+03  9.5900e+02  6.4950e+03  2.5105e+04\n",
       "  1.4100e+02  5.8580e+03  4.9000e+01  2.8400e+02  7.0000e+00  2.7800e+02\n",
       "  1.0000e+01  6.3900e+02  3.4800e+02  3.1010e+03  6.8000e+01  2.8000e+01\n",
       "  1.7300e+02  2.4793e+04  1.6400e+02  2.0700e+02  5.6300e+02  1.3100e+02\n",
       "  4.8000e+01  2.2740e+03  2.8000e+01  1.6600e+02  1.2400e+02  4.2000e+01\n",
       "  1.4105e+04  1.1000e+02  5.0397e+04  5.6000e+02  1.3000e+01  5.0000e+00\n",
       "  4.6000e+02  2.0000e+01  3.1800e+02  3.1000e+01  2.0000e+00  1.3077e+04\n",
       "  5.1690e+03  4.6200e+02  4.2000e+01  2.0000e+00  1.0900e+02  2.0000e+00\n",
       "  2.7400e+02  1.1085e+04  1.8100e+02  1.3319e+04  3.3740e+03  1.3210e+03\n",
       " \n",
       " Columns 54 to 59 \n",
       "  3.7852e+05  5.0700e+02  3.6600e+02  1.8100e+02  8.0000e+00  7.0000e+00\n",
       "  6.6640e+03  2.1835e+04  5.5000e+01  2.0000e+00  2.1530e+03  4.7000e+01\n",
       "  9.0000e+01  1.4000e+01  1.4000e+01  1.4074e+04  5.1820e+03  5.5700e+02\n",
       "  8.0000e+00  1.3100e+02  9.0000e+00  8.1000e+01  3.4872e+04  2.0000e+00\n",
       "  2.7900e+02  7.9000e+01  6.0000e+00  1.1246e+05  3.8600e+02  2.5510e+03\n",
       "  2.0400e+02  1.7000e+01  1.8700e+02  4.6910e+03  1.2330e+03  2.7238e+05\n",
       "  3.7433e+05  6.0000e+00  4.0000e+00  5.0000e+00  2.3000e+01  3.2006e+05\n",
       "  1.9000e+01  2.0060e+03  4.5000e+01  8.8000e+03  2.2000e+01  8.2824e+04\n",
       "  6.7200e+03  4.0000e+00  8.2820e+03  3.3578e+04  5.2205e+04  2.5310e+05\n",
       " \n",
       " Columns 60 to 63 \n",
       "  3.6000e+01  3.8147e+05  1.8000e+01  1.5300e+02\n",
       "  7.0000e+00  1.5850e+03  2.1400e+02  1.3760e+03\n",
       "  1.3700e+02  5.0000e+00  4.3000e+01  6.0000e+00\n",
       "  1.4000e+01  6.1000e+01  1.2400e+02  3.2417e+05\n",
       "  1.7800e+02  3.1740e+03  1.3000e+01  5.2700e+02\n",
       "  3.0000e+00  2.1000e+01  2.2000e+01  1.9700e+02\n",
       "  2.0000e+00  1.5900e+02  4.0100e+02  5.4100e+02\n",
       "  4.2000e+01  4.3800e+02  2.0211e+04  1.9700e+02\n",
       "  2.6072e+05  1.8115e+04  1.8000e+01  6.5720e+03\n",
       " [torch.cuda.LongTensor of size 9x64 (GPU 0)], Variable containing:\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     1     0     0     1     1     0\n",
       "     1     0     0     1     1     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     1     0     0     1     1     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     1     1     0     1     1     0\n",
       "     0     0     0     0     0     0\n",
       "     1     0     0     1     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     1     0     0     1     0     0\n",
       "     1     0     0     0     0     0\n",
       "     1     0     0     1     1     0\n",
       "     0     0     0     0     0     0\n",
       "     1     0     0     1     1     0\n",
       "     1     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     1     0     0     1     1     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     1     1     0     1     0     0\n",
       "     1     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     1     0     0     0     0     1\n",
       "     1     0     0     1     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     1     0     0     0     1     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     1     0\n",
       "     0     0     0     0     0     0\n",
       "     0     0     0     0     0     0\n",
       " [torch.cuda.FloatTensor of size 64x6 (GPU 0)])"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(train_dl.__iter__())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're ready to start training a model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a Text Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use a simple LSTM as a baseline example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleBiLSTMBaseline(nn.Module):\n",
    "    def __init__(self, hidden_dim, emb_dim=300,\n",
    "                 spatial_dropout=0.05, recurrent_dropout=0.1, num_linear=1):\n",
    "        super().__init__() # don't forget to call this!\n",
    "        self.embedding = nn.Embedding(len(TEXT.vocab), emb_dim)\n",
    "        self.encoder = nn.LSTM(emb_dim, hidden_dim, num_layers=1, dropout=recurrent_dropout)\n",
    "        self.linear_layers = []\n",
    "        for _ in range(num_linear - 1):\n",
    "            self.linear_layers.append(nn.Linear(hidden_dim, hidden_dim))\n",
    "        self.linear_layers = nn.ModuleList(self.linear_layers)\n",
    "        self.predictor = nn.Linear(hidden_dim, 6)\n",
    "    \n",
    "    def forward(self, seq):\n",
    "        hdn, _ = self.encoder(self.embedding(seq))\n",
    "        feature = hdn[-1, :, :]\n",
    "        for layer in self.linear_layers:\n",
    "            feature = layer(feature)\n",
    "        preds = self.predictor(feature)\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleBiLSTMBaseline(\n",
       "  (embedding): Embedding(386045, 100)\n",
       "  (encoder): LSTM(100, 500, dropout=0.1)\n",
       "  (linear_layers): ModuleList(\n",
       "  )\n",
       "  (predictor): Linear(in_features=500, out_features=6)\n",
       ")"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em_sz = 100\n",
    "nh = 500\n",
    "nl = 3\n",
    "model = SimpleBiLSTMBaseline(nh, emb_dim=em_sz); model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're using a GPU, remember to call model.cuda() to move your model to the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleBiLSTMBaseline(\n",
       "  (embedding): Embedding(386045, 100)\n",
       "  (encoder): LSTM(100, 500, dropout=0.1)\n",
       "  (linear_layers): ModuleList(\n",
       "  )\n",
       "  (predictor): Linear(in_features=500, out_features=6)\n",
       ")"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optim.Adam(model.parameters(), lr=1e-2)\n",
    "loss_func = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████▉| 1869/1870 [00:52<00:00, 35.89it/s]C:\\Users\\hafid\\Dropbox\\3.SelfStudy\\ml_lab\\Anaconda3\\envs\\fastai\\lib\\site-packages\\ipykernel_launcher.py:6: DeprecationWarning: generator 'Iterator.__iter__' raised StopIteration\n",
      "  \n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1870/1870 [00:52<00:00, 35.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Training Loss: 0.0445, Validation Loss: 0.0663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1870/1870 [00:51<00:00, 36.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Training Loss: 0.0402, Validation Loss: 0.0627\n",
      "Wall time: 1min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in range(1, epochs + 1):\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    model.train() # turn on training mode\n",
    "    for x, y in tqdm.tqdm(train_dl): # thanks to our wrapper, we can intuitively iterate over our data!\n",
    "        opt.zero_grad()\n",
    "\n",
    "        preds = model(x)\n",
    "        loss = loss_func(preds, y)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        \n",
    "        running_loss += loss.data[0] * x.size(0)\n",
    "        \n",
    "    epoch_loss = running_loss / len(trn)\n",
    "    \n",
    "    # calculate the validation loss for this epoch\n",
    "    val_loss = 0.0\n",
    "    model.eval() # turn on evaluation mode\n",
    "    for x, y in valid_dl:\n",
    "        preds = model(x)\n",
    "        loss = loss_func(preds, y)\n",
    "        val_loss += loss.data[0] * x.size(0)\n",
    "\n",
    "    val_loss /= len(vld)\n",
    "    print('Epoch: {}, Training Loss: {:.4f}, Validation Loss: {:.4f}'.format(epoch, epoch_loss, val_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.BatchWrapper at 0x1816cb26a90>"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████▉| 2392/2394 [01:46<00:00, 22.50it/s]C:\\Users\\hafid\\Dropbox\\3.SelfStudy\\ml_lab\\Anaconda3\\envs\\fastai\\lib\\site-packages\\ipykernel_launcher.py:6: DeprecationWarning: generator 'Iterator.__iter__' raised StopIteration\n",
      "  \n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 2394/2394 [01:46<00:00, 22.51it/s]\n"
     ]
    }
   ],
   "source": [
    "test_preds = []\n",
    "for x, y in tqdm.tqdm(test_dl):\n",
    "    preds = model(x)\n",
    "    # if you're data is on the GPU, you need to move the data back to the cpu\n",
    "    preds = preds.data.cpu().numpy()\n",
    "#     preds = preds.data.numpy()\n",
    "    # the actual outputs of the model are logits, so we need to pass these values to the sigmoid function\n",
    "    preds = 1 / (1 + np.exp(-preds))\n",
    "    test_preds.append(preds)\n",
    "test_preds = np.vstack(test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'BatchWrapper' object does not support indexing",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-429-762bbeff46c8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest_dl\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'BatchWrapper' object does not support indexing"
     ]
    }
   ],
   "source": [
    "test_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153164"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153164"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(TEST_PATH)\n",
    "for i, col in enumerate([\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]):\n",
    "    df[col] = test_preds[:, i]\n",
    "\n",
    "# if you want to write the submission file to disk, uncomment and run the below code\n",
    "df.drop(\"comment_text\", axis=1).to_csv(\"C://Users/hafid/Dropbox/3.SelfStudy/kaggle/ai6-kaggle-toxic/submission/multi-label-bilstm-2.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>Yo bitch Ja Rule is more succesful then you'll...</td>\n",
       "      <td>0.023659</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>1.008396e-05</td>\n",
       "      <td>0.007243</td>\n",
       "      <td>0.014948</td>\n",
       "      <td>0.000581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>== From RfC ==    The title is fine as it is, ...</td>\n",
       "      <td>0.001512</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>5.643992e-06</td>\n",
       "      <td>0.000550</td>\n",
       "      <td>0.000892</td>\n",
       "      <td>0.000049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>\"    == Sources ==    * Zawe Ashton on Lapland...</td>\n",
       "      <td>0.001571</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>4.825711e-07</td>\n",
       "      <td>0.000925</td>\n",
       "      <td>0.000823</td>\n",
       "      <td>0.000046</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  \\\n",
       "0  00001cee341fdb12  Yo bitch Ja Rule is more succesful then you'll...   \n",
       "1  0000247867823ef7  == From RfC ==    The title is fine as it is, ...   \n",
       "2  00013b17ad220c46  \"    == Sources ==    * Zawe Ashton on Lapland...   \n",
       "\n",
       "      toxic  severe_toxic       obscene    threat    insult  identity_hate  \n",
       "0  0.023659      0.000054  1.008396e-05  0.007243  0.014948       0.000581  \n",
       "1  0.001512      0.000016  5.643992e-06  0.000550  0.000892       0.000049  \n",
       "2  0.001571      0.000003  4.825711e-07  0.000925  0.000823       0.000046  "
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
