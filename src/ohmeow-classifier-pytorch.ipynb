{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext\n",
    "from torchtext import vocab, data\n",
    "from torchtext.datasets import language_modeling\n",
    "\n",
    "from fastai.rnn_reg import *\n",
    "from fastai.rnn_train import *\n",
    "from fastai.nlp import *\n",
    "from fastai.lm_rnn import *\n",
    "from fastai.structured import *\n",
    "from fastai import sgdr\n",
    "\n",
    "import spacy\n",
    "spacy_en = spacy.load('en')\n",
    "\n",
    "import dill as pickle\n",
    "\n",
    "# pandas and plotting config\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0.3724  0.2573  0.7300\n",
      " 0.2363  0.3384  0.1287\n",
      "[torch.cuda.FloatTensor of size 2x3 (GPU 0)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch; print(torch.rand(2,3).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### run this if tqdm goes crazy (see http://forums.fast.ai/t/a-christmas-gift/9163?u=wgpubs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm import tqdm as tqdm_cls\n",
    "# inst = tqdm_cls._instances\n",
    "# for i in range(len(inst)): inst.pop().close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"C://Users/hafid/Dropbox/3.SelfStudy/kaggle/ai6-kaggle-toxic/data/train/train.csv\")\n",
    "test = pd.read_csv(\"C://Users/hafid/Dropbox/3.SelfStudy/kaggle/ai6-kaggle-toxic/data/test/test.csv\")\n",
    "# subm = pd.read_csv(\"C://Users/hafid\\Dropbox/3.SelfStudy/kaggle/jigsaw-toxic-comment-classification/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH='C://Users/hafid/Dropbox/3.SelfStudy/kaggle/ai6-kaggle-toxic/'\n",
    "\n",
    "TRN_PATH = 'data/train/'\n",
    "VAL_PATH = 'data/test/'\n",
    "TRN = f'{PATH}{TRN_PATH}'\n",
    "VAL = f'{PATH}{VAL_PATH}'\n",
    "\n",
    "os.listdir(PATH)\n",
    "\n",
    "train = pd.read_csv(f'{TRN}train.csv')\n",
    "test = pd.read_csv(f'{VAL}test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 159571 | Test size: 153164\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, January 11, 2016 (UTC)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It's just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. He seems to care more about the formatting than the actual info.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  \\\n",
       "0  0000997932d777bf   \n",
       "1  000103f0d9cfb60f   \n",
       "2  000113f07ec002fd   \n",
       "\n",
       "                                                                                                                                                                                                                                                                comment_text  \\\n",
       "0  Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27   \n",
       "1  D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, January 11, 2016 (UTC)                                                                                                                                                            \n",
       "2  Hey man, I'm really not trying to edit war. It's just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. He seems to care more about the formatting than the actual info.                                   \n",
       "\n",
       "   toxic  severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0  0      0             0        0       0       0              \n",
       "1  0      0             0        0       0       0              \n",
       "2  0      0             0        0       0       0              "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>Yo bitch Ja Rule is more succesful then you'll ever be whats up with you and hating you sad mofuckas...i should bitch slap ur pethedic white faces and get you to kiss my ass you guys sicken me. Ja rule is about pride in da music man. dont diss that shit on him. and nothin is wrong bein like tupac he was a brother too...fuckin white boys get things right next time.,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>== From RfC == \\n\\n The title is fine as it is, IMO.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>\" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lapland —  /  \"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  \\\n",
       "0  00001cee341fdb12   \n",
       "1  0000247867823ef7   \n",
       "2  00013b17ad220c46   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                      comment_text  \n",
       "0  Yo bitch Ja Rule is more succesful then you'll ever be whats up with you and hating you sad mofuckas...i should bitch slap ur pethedic white faces and get you to kiss my ass you guys sicken me. Ja rule is about pride in da music man. dont diss that shit on him. and nothin is wrong bein like tupac he was a brother too...fuckin white boys get things right next time.,  \n",
       "1  == From RfC == \\n\\n The title is fine as it is, IMO.                                                                                                                                                                                                                                                                                                                             \n",
       "2  \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lapland —  /  \"                                                                                                                                                                                                                                                                                                                       "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f'Train size: {len(train)} | Test size: {len(test)}')\n",
    "display(train.head(3))\n",
    "display(test.head(3))\n",
    "# display(sample_subm_df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We take a look at the overall statistics of the data. Also included another label named 'none' to represent comments that have no negative sentiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>none</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>159571</td>\n",
       "      <td>159571</td>\n",
       "      <td>159571</td>\n",
       "      <td>159571</td>\n",
       "      <td>159571</td>\n",
       "      <td>159571</td>\n",
       "      <td>159571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0958445</td>\n",
       "      <td>0.00999555</td>\n",
       "      <td>0.0529482</td>\n",
       "      <td>0.00299553</td>\n",
       "      <td>0.0493636</td>\n",
       "      <td>0.00880486</td>\n",
       "      <td>0.898321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.294379</td>\n",
       "      <td>0.0994771</td>\n",
       "      <td>0.223931</td>\n",
       "      <td>0.0546496</td>\n",
       "      <td>0.216627</td>\n",
       "      <td>0.0934205</td>\n",
       "      <td>0.302226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>counts</th>\n",
       "      <td>159571</td>\n",
       "      <td>159571</td>\n",
       "      <td>159571</td>\n",
       "      <td>159571</td>\n",
       "      <td>159571</td>\n",
       "      <td>159571</td>\n",
       "      <td>159571</td>\n",
       "      <td>159571</td>\n",
       "      <td>159571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uniques</th>\n",
       "      <td>159571</td>\n",
       "      <td>159571</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>missing</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>missing_perc</th>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "      <td>0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>types</th>\n",
       "      <td>unique</td>\n",
       "      <td>unique</td>\n",
       "      <td>bool</td>\n",
       "      <td>bool</td>\n",
       "      <td>bool</td>\n",
       "      <td>bool</td>\n",
       "      <td>bool</td>\n",
       "      <td>bool</td>\n",
       "      <td>bool</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id comment_text      toxic severe_toxic    obscene  \\\n",
       "count         NaN     NaN          159571     159571       159571      \n",
       "mean          NaN     NaN          0.0958445  0.00999555   0.0529482   \n",
       "std           NaN     NaN          0.294379   0.0994771    0.223931    \n",
       "min           NaN     NaN          0          0            0           \n",
       "25%           NaN     NaN          0          0            0           \n",
       "50%           NaN     NaN          0          0            0           \n",
       "75%           NaN     NaN          0          0            0           \n",
       "max           NaN     NaN          1          1            1           \n",
       "counts        159571  159571       159571     159571       159571      \n",
       "uniques       159571  159571       2          2            2           \n",
       "missing       0       0            0          0            0           \n",
       "missing_perc  0%      0%           0%         0%           0%          \n",
       "types         unique  unique       bool       bool         bool        \n",
       "\n",
       "                  threat     insult identity_hate      none  \n",
       "count         159571      159571     159571        159571    \n",
       "mean          0.00299553  0.0493636  0.00880486    0.898321  \n",
       "std           0.0546496   0.216627   0.0934205     0.302226  \n",
       "min           0           0          0             0         \n",
       "25%           0           0          0             1         \n",
       "50%           0           0          0             1         \n",
       "75%           0           0          0             1         \n",
       "max           1           1          1             1         \n",
       "counts        159571      159571     159571        159571    \n",
       "uniques       2           2          2             2         \n",
       "missing       0           0          0             0         \n",
       "missing_perc  0%          0%         0%            0%        \n",
       "types         bool        bool       bool          bool      "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "train['none'] = 1 - train[label_cols].max(axis=1)\n",
    "\n",
    "DataFrameSummary(train).summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://drive.google.com/file/d/0B1yuv8YaUVlZZ1RzMFJmc1ZsQmM/view\n",
    "# Aphost lookup dict\n",
    "APPO = {\n",
    "\"aren't\" : \"are not\",\n",
    "\"can't\" : \"cannot\",\n",
    "\"couldn't\" : \"could not\",\n",
    "\"didn't\" : \"did not\",\n",
    "\"doesn't\" : \"does not\",\n",
    "\"don't\" : \"do not\",\n",
    "\"hadn't\" : \"had not\",\n",
    "\"hasn't\" : \"has not\",\n",
    "\"haven't\" : \"have not\",\n",
    "\"he'd\" : \"he would\",\n",
    "\"he'll\" : \"he will\",\n",
    "\"he's\" : \"he is\",\n",
    "\"i'd\" : \"I would\",\n",
    "\"i'd\" : \"I had\",\n",
    "\"i'll\" : \"I will\",\n",
    "\"i'm\" : \"I am\",\n",
    "\"isn't\" : \"is not\",\n",
    "\"it's\" : \"it is\",\n",
    "\"it'll\":\"it will\",\n",
    "\"i've\" : \"I have\",\n",
    "\"let's\" : \"let us\",\n",
    "\"mightn't\" : \"might not\",\n",
    "\"mustn't\" : \"must not\",\n",
    "\"shan't\" : \"shall not\",\n",
    "\"she'd\" : \"she would\",\n",
    "\"she'll\" : \"she will\",\n",
    "\"she's\" : \"she is\",\n",
    "\"shouldn't\" : \"should not\",\n",
    "\"that's\" : \"that is\",\n",
    "\"there's\" : \"there is\",\n",
    "\"they'd\" : \"they would\",\n",
    "\"they'll\" : \"they will\",\n",
    "\"they're\" : \"they are\",\n",
    "\"they've\" : \"they have\",\n",
    "\"we'd\" : \"we would\",\n",
    "\"we're\" : \"we are\",\n",
    "\"weren't\" : \"were not\",\n",
    "\"we've\" : \"we have\",\n",
    "\"what'll\" : \"what will\",\n",
    "\"what're\" : \"what are\",\n",
    "\"what's\" : \"what is\",\n",
    "\"what've\" : \"what have\",\n",
    "\"where's\" : \"where is\",\n",
    "\"who'd\" : \"who would\",\n",
    "\"who'll\" : \"who will\",\n",
    "\"who're\" : \"who are\",\n",
    "\"who's\" : \"who is\",\n",
    "\"who've\" : \"who have\",\n",
    "\"won't\" : \"will not\",\n",
    "\"wouldn't\" : \"would not\",\n",
    "\"you'd\" : \"you would\",\n",
    "\"you'll\" : \"you will\",\n",
    "\"you're\" : \"you are\",\n",
    "\"you've\" : \"you have\",\n",
    "\"'re\": \" are\",\n",
    "\"wasn't\": \"was not\",\n",
    "\"we'll\":\" will\",\n",
    "\"didn't\": \"did not\",\n",
    "\"tryin'\":\"trying\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hafid\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\hafid\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "eng_stopwords = set(stopwords.words(\"english\"))\n",
    "lem = WordNetLemmatizer()\n",
    "tweet_tokenizer=TweetTokenizer()\n",
    "\n",
    "def clean(comment):\n",
    "    \"\"\"\n",
    "    This function receives comments and returns clean word-list\n",
    "    \"\"\"\n",
    "    #Convert to lower case , so that Hi and hi are the same\n",
    "    comment=comment.lower()\n",
    "    #remove \\n\n",
    "    comment=re.sub(\"\\\\n\",\"\",comment)\n",
    "    # remove leaky elements like ip,user\n",
    "    comment=re.sub(\"\\d{1,3}.\\d{1,3}.\\d{1,3}.\\d{1,3}\",\"\",comment)\n",
    "    #removing usernames\n",
    "    comment=re.sub(\"\\[\\[.*\\]\",\"\",comment)\n",
    "    \n",
    "    #Split the sentences into words\n",
    "    words=tweet_tokenizer.tokenize(comment)\n",
    "    \n",
    "    # (')aphostophe  replacement (ie)   you're --> you are  \n",
    "    # ( basic dictionary lookup : master dictionary present in a hidden block of code)\n",
    "    words=[APPO[word] if word in APPO else word for word in words]\n",
    "    words=[lem.lemmatize(word, \"v\") for word in words]\n",
    "    words = [w for w in words if not w in eng_stopwords]\n",
    "    \n",
    "    clean_sent=\" \".join(words)\n",
    "    # remove any non alphanum,digit character\n",
    "    #clean_sent=re.sub(\"\\W+\",\" \",clean_sent)\n",
    "    #clean_sent=re.sub(\"  \",\" \",clean_sent)\n",
    "    return(clean_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['clean_comment_text'] = train.comment_text.apply(lambda x: clean(x))\n",
    "test['clean_comment_text'] = test.comment_text.apply(lambda x: clean(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Dataset and ModelData Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextMultiLabelDataset(torchtext.data.Dataset):\n",
    "    def __init__(self, df, tt_text_field, tt_label_field, txt_col, lbl_cols, **kwargs):\n",
    "        # torchtext Field objects\n",
    "        fields = [('text', tt_text_field)]\n",
    "        for l in lbl_cols: fields.append((l, tt_label_field))\n",
    "            \n",
    "        is_test = False if lbl_cols[0] in df.columns else True\n",
    "        n_labels = len(lbl_cols)\n",
    "        \n",
    "        examples = []\n",
    "        for idx, row in df.iterrows():\n",
    "            if not is_test:\n",
    "                lbls = [ row[l] for l in lbl_cols ]\n",
    "            else:\n",
    "                lbls = [0.0] * n_labels\n",
    "                \n",
    "            txt = str(row[txt_col])\n",
    "            examples.append(data.Example.fromlist([txt]+lbls, fields))\n",
    "                            \n",
    "        super().__init__(examples, fields, **kwargs)\n",
    "\n",
    "    @staticmethod\n",
    "    def sort_key(example): \n",
    "        return len(example.text)\n",
    "    \n",
    "    @classmethod\n",
    "    def splits(cls, text_field, label_field, train_df, txt_col, lbl_cols, val_df=None, test_df=None, **kwargs):\n",
    "        # build train, val, and test data\n",
    "        train_data, val_data, test_data = (None, None, None)\n",
    "        \n",
    "        if train_df is not None: \n",
    "            train_data = cls(train_df.copy(), text_field, label_field, txt_col, lbl_cols, **kwargs)\n",
    "        if val_df is not None: \n",
    "            val_data = cls(val_df.copy(), text_field, label_field, txt_col, lbl_cols, **kwargs)\n",
    "        if test_df is not None: \n",
    "            test_data = cls(test_df.copy(), text_field, label_field, txt_col, lbl_cols, **kwargs)\n",
    "\n",
    "        return tuple(d for d in (train_data, val_data, test_data) if d is not None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextMultiLabelDataLoader():\n",
    "    def __init__(self, src, x_fld, y_flds, y_dtype='torch.cuda.FloatTensor'):\n",
    "        self.src, self.x_fld, self.y_flds = src, x_fld, y_flds\n",
    "        self.y_dtype = y_dtype\n",
    "\n",
    "    def __len__(self): return len(self.src)#-1\n",
    "\n",
    "    def __iter__(self):\n",
    "        it = iter(self.src)\n",
    "        for i in range(len(self)):\n",
    "            b = next(it)\n",
    "            \n",
    "            if (len(self.y_flds) > 1):\n",
    "                targ = [ getattr(b, y) for y in self.y_flds ] \n",
    "                targ = torch.stack(targ, dim=1).type(self.y_dtype)\n",
    "            else: \n",
    "                targ = getattr(b, self.y_flds[0])\n",
    "                targ = targ.type(self.y_dtype)\n",
    "\n",
    "            yield getattr(b, self.x_fld), targ\n",
    "\n",
    "class TextMultiLabelData(ModelData):\n",
    "\n",
    "    @classmethod\n",
    "    def from_splits(cls, path, splits, bs, text_name='text', label_names=['label'], \n",
    "                    target_dtype='torch.cuda.FloatTensor'):\n",
    "        \n",
    "        text_fld = splits[0].fields[text_name]\n",
    "        \n",
    "        label_flds = []\n",
    "        if (len(label_names) == 1): \n",
    "            label_fld = splits[0].fields[label_names[0]]\n",
    "            label_flds.append(label_fld)\n",
    "            if (label_fld.use_vocab): \n",
    "                label_fld.build_vocab(splits[0])\n",
    "                target_dtype = 'torch.cuda.LongTensor'\n",
    "        else:\n",
    "            for n in label_names:\n",
    "                label_fld = splits[0].fields[n]\n",
    "                label_flds.append(label_fld)\n",
    "\n",
    "        iters = torchtext.data.BucketIterator.splits(splits, batch_size=bs)\n",
    "        trn_iter,val_iter,test_iter = iters[0],iters[1],None\n",
    "        test_dl = None\n",
    "        if len(iters) == 3:\n",
    "            test_iter = iters[2]\n",
    "            test_dl = TextMultiLabelDataLoader(test_iter, text_name, label_names, target_dtype)\n",
    "        trn_dl = TextMultiLabelDataLoader(trn_iter, text_name, label_names, target_dtype)\n",
    "        val_dl = TextMultiLabelDataLoader(val_iter, text_name, label_names, target_dtype)\n",
    "\n",
    "        obj = cls.from_dls(path, trn_dl, val_dl, test_dl)\n",
    "        obj.bs = bs\n",
    "        obj.pad_idx = text_fld.vocab.stoi[text_fld.pad_token]\n",
    "        obj.nt = len(text_fld.vocab)\n",
    "\n",
    "        # if multiple labels, assume the # of classes = the # of labels \n",
    "        if (len(label_names) > 1):\n",
    "            c = len(label_names)\n",
    "        # if label has a vocab, assume the vocab represents the # of classes\n",
    "        elif (hasattr(label_flds[0], 'vocab')): \n",
    "            c = len(label_flds[0].vocab)\n",
    "        else:\n",
    "            c = 1\n",
    "            \n",
    "        obj.c = c\n",
    "\n",
    "        return obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, string\n",
    "re_tok = re.compile(f'([{string.punctuation}“”¨«»®´·º½¾¿¡§£₤‘’])')\n",
    "def tokenizer(s): return re_tok.sub(r' \\1 ', s).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "bsz = 8 #16 #32 #64\n",
    "\n",
    "max_tokens = 20000 # max number of words based on frequency\n",
    "max_len = None #100      # max length of each comment to look at\n",
    "\n",
    "n_hidden = 256\n",
    "n_fac = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LstmClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, n_fac, bsz, \n",
    "                 fc_szs=[], fc_drops=[], n_lstm_hidden=256, n_lstm_layers=1, out_sz=1,\n",
    "                 lstm_drop=0.5, is_multi=False, y_range=None, use_bn=False):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.vocab_size, self.out_sz = vocab_size, out_sz\n",
    "        self.n_lstm_layers, self.n_lstm_hidden = n_lstm_layers, n_lstm_hidden\n",
    "        \n",
    "        self.is_multi = is_multi\n",
    "        self.y_range = y_range\n",
    "        self.use_bn = use_bn\n",
    "        \n",
    "        self.e = nn.Embedding(vocab_size, n_fac)\n",
    "        self.e.weight.data.uniform_(-0.1, 0.1)\n",
    "        \n",
    "        self.rnn = nn.LSTM(n_fac, n_lstm_hidden, n_lstm_layers, dropout=lstm_drop)\n",
    "        \n",
    "        fc_szs = [n_lstm_hidden] + fc_szs\n",
    "        \n",
    "        self.linears, self.linear_drops, self.linear_bns = [], [], []\n",
    "        if (len(fc_szs) > 1):\n",
    "            self.linears = nn.ModuleList(\n",
    "                [ nn.Linear(fc_szs[idx], sz) for idx, sz in enumerate(fc_szs[1:]) ]\n",
    "            )\n",
    "            \n",
    "            self.linear_bns = nn.ModuleList(\n",
    "                [ nn.BatchNorm1d(sz) for sz in fc_szs[1:] ]\n",
    "            )\n",
    "            \n",
    "            for l in self.linears: kaiming_normal(l.weight.data)\n",
    "                \n",
    "        if (len(fc_drops) > 0):\n",
    "            self.linear_drops = nn.ModuleList([ nn.Dropout(d) for d in fc_drops ])\n",
    "                \n",
    "        self.outp = nn.Linear(fc_szs[-1], out_sz)\n",
    "        kaiming_normal(self.outp.weight.data)\n",
    "            \n",
    "        self.h = self.init_hidden(bsz)\n",
    "        \n",
    "    def forward(self, words):\n",
    "        bsz = words[0].size(0)\n",
    "        if (self.h[0].size(1) != bsz): self.h = self.init_hidden(bsz)\n",
    "            \n",
    "        x, h = self.rnn(self.e(words), self.h)\n",
    "        self.h = repackage_var(h)\n",
    "        \n",
    "        x = x[-1]\n",
    "        \n",
    "        for l, d, b in zip(self.linears, self.linear_drops, self.linear_bns):\n",
    "            x = F.relu(l(x))\n",
    "            if (self.use_bn): x = b(x)\n",
    "            x = d(x)\n",
    "        \n",
    "        x = self.outp(x)\n",
    "\n",
    "        if (self.is_multi):\n",
    "            return F.sigmoid(x)\n",
    "        \n",
    "        if (not self.is_multi and self.out_sz > 1):\n",
    "            return F.log_softmax(x)\n",
    "        \n",
    "        if (self.y_range):\n",
    "            x = F.sigmoid(x)\n",
    "            x = x * (self.y_range[1] - self.y_range[0])\n",
    "            x = x + self.y_range[0]\n",
    "            \n",
    "        return x\n",
    "    \n",
    "    def init_hidden(self, bsz):\n",
    "        return(V(torch.zeros(self.n_lstm_layers, bsz, self.n_lstm_hidden)), \n",
    "               V(torch.zeros(self.n_lstm_layers, bsz, self.n_lstm_hidden)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi label classification\n",
    "Predict class probabilities where multiple classes can be true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159412, 159, 153164)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt_col = 'comment_text'\n",
    "\n",
    "val_idxs = get_cv_idxs(len(train), val_pct=0.001)\n",
    "\n",
    "train_df =  train.drop(val_idxs)\n",
    "val_df = train.copy().iloc[val_idxs]\n",
    "\n",
    "len(train_df), len(val_df), len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                    object \n",
       "comment_text          object \n",
       "toxic                 float32\n",
       "severe_toxic          float32\n",
       "obscene               float32\n",
       "threat                float32\n",
       "insult                float32\n",
       "identity_hate         float32\n",
       "none                  float32\n",
       "clean_comment_text    object \n",
       "dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ensure target fields are the correct datatype\n",
    "train_df[label_cols + ['none']] = train_df[label_cols + ['none']].astype(np.float32)\n",
    "val_df[label_cols + ['none']] = val_df[label_cols + ['none']].astype(np.float32)\n",
    "\n",
    "train_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since our label is essentially a OHE vector, set use_vocab=False for the label's torchtext field\n",
    "tt_TEXT = data.Field(sequential=True, tokenize=tokenizer, fix_length=max_len)\n",
    "tt_LABEL = data.Field(sequential=False, use_vocab=False,tensor_type=torch.cuda.FloatTensor) # use_vocab=False if labels are numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = TextMultiLabelDataset.splits(tt_TEXT, tt_LABEL, train_df, \n",
    "                                      txt_col, label_cols, val_df, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0,\n",
       " 0.0,\n",
       " \"Explanation Why the edits made under my username Hardcore Metallica Fan were reverted ? They weren ' t vandalisms , just closure on some GAs after I voted at New York Dolls FAC . And please don ' t remove the template from the talk page since I ' m retired now . 89 . 205 . 38 . 27\")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ------ multi-label problem ------\n",
    "t = splits[0].examples[0]\n",
    "t.toxic, t.insult, ' '.join(t.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_TEXT.build_vocab(splits[0], max_size=max_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19927, 20002, 6)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md = TextMultiLabelData.from_splits(PATH, splits, bsz, text_name='text', label_names=label_cols)\n",
    "\n",
    "len(md.trn_dl), md.nt, md.c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = next(iter(md.val_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 6]), Variable containing:\n",
       "  0  0  0  0  0  0\n",
       "  0  0  0  0  0  0\n",
       "  1  0  1  0  1  1\n",
       "  0  0  0  0  0  0\n",
       "  0  0  0  0  0  0\n",
       " [torch.cuda.FloatTensor of size 5x6 (GPU 0)])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.size(), y[:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "md.val_dl.it.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "['<unk>', '<pad>', '.', ',', 'the', '\"', 'to', 'I', 'of', \"'\"]\n"
     ]
    }
   ],
   "source": [
    "print(tt_TEXT.vocab.stoi[tt_TEXT.pad_token])\n",
    "print(tt_TEXT.vocab.itos[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "most common words: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('.', 679644),\n",
       " (',', 474397),\n",
       " ('the', 448846),\n",
       " ('\"', 392207),\n",
       " ('to', 291675),\n",
       " ('I', 224237),\n",
       " ('of', 221226),\n",
       " (\"'\", 219203),\n",
       " ('and', 212449),\n",
       " ('a', 203738)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('most common words: ')\n",
    "tt_TEXT.vocab.freqs.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "least common words: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Gag01001', 1),\n",
       " ('Aberration', 1),\n",
       " ('1053', 1),\n",
       " ('Hanumakonda', 1),\n",
       " ('956CE', 1),\n",
       " ('automakers', 1),\n",
       " ('Boastful', 1),\n",
       " ('Superlatives', 1),\n",
       " ('Classifying', 1),\n",
       " ('CIU', 1)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('least common words: ')\n",
    "tt_TEXT.vocab.freqs.most_common()[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = LstmClassifier(md.nt, n_fac, bsz, [512, 256], [0.4, 0.2],\n",
    "                   n_hidden, n_lstm_layers=1, out_sz=md.c, is_multi=True, use_bn=True).cuda()\n",
    "\n",
    "lo = LayerOptimizer(optim.Adam, m, 1e-3, 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf8dc74679964d57a489885a082a31da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                                                                         \n",
      "    0      0.079206   0.061075  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.061074965]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(m, md, 1, lo.opt, F.binary_cross_entropy) \n",
    "# use F.binary_cross_entropy for multi-label problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2455493a34e44b9eb3dcf0ed598c3181",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=15), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                                                                         \n",
      "    0      0.058427   0.060934  \n",
      "    1      0.065899   0.062487                                                                                         \n",
      "    2      0.072444   0.067923                                                                                         \n",
      "    3      0.067772   0.059789                                                                                         \n",
      "    4      0.073532   0.080633                                                                                         \n",
      "    5      0.065131   0.062281                                                                                         \n",
      "    6      0.073936   0.06749                                                                                          \n",
      "    7      0.072784   0.070267                                                                                         \n",
      "    8      0.076176   0.061119                                                                                         \n",
      "    9      0.075846   0.059845                                                                                         \n",
      "    10     0.084086   0.082739                                                                                         \n",
      "    11     0.063994   0.059244                                                                                         \n",
      "    12     0.061395   0.068037                                                                                         \n",
      "    13     0.077991   0.063504                                                                                         \n",
      "    14     0.059791   0.071739                                                                                         \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.071738586]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4 cycles of len 1, 2, 4, 8\n",
    "\n",
    "on_end = lambda sched, cycle: save_model(m, f'{PATH}/models/multi-label-cyc_{cycle}-of-4')\n",
    "cb = [CosAnneal(lo, len(md.trn_dl), cycle_mult=2, on_cycle_end=on_end)]\n",
    "\n",
    "fit(m, md, 2**4-1, lo.opt, F.binary_cross_entropy, callbacks=cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1798dc4a7734841a9f0e9a1e886c193",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                                                                         \n",
      "    0      0.07838    0.066901  \n",
      "    1      0.078732   0.071679                                                                                         \n",
      "    2      0.077724   0.060586                                                                                         \n",
      "    3      0.079049   0.061932                                                                                         \n",
      "    4      0.076698   0.059966                                                                                         \n",
      "    5      0.065333   0.061721                                                                                         \n",
      "    6      0.064976   0.062056                                                                                         \n",
      "    7      0.068952   0.058685                                                                                         \n",
      "    8      0.049348   0.054012                                                                                         \n",
      "    9      0.052222   0.060072                                                                                         \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.060072284]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "on_end = lambda sched, cycle: save_model(m, f'{PATH}/models/multi-label-2-cyc_{cycle}-of-1')\n",
    "cb = [CosAnneal(lo, len(md.trn_dl) * 10, on_cycle_end=on_end)]\n",
    "\n",
    "fit(m, md, 10, lo.opt, F.binary_cross_entropy, callbacks=cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model(m, f'{PATH}/models/multi-label-2-cyc_0-of-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153164, 153164, 159571, 159)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "preds = predict(m, md.test_dl)\n",
    "len(preds), len(test), len(train), len(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>153144</th>\n",
       "      <td>fff7159b3ee95618</td>\n",
       "      <td>0.866605</td>\n",
       "      <td>0.160197</td>\n",
       "      <td>0.690027</td>\n",
       "      <td>0.040850</td>\n",
       "      <td>0.636490</td>\n",
       "      <td>0.114437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153145</th>\n",
       "      <td>fff718ffe5f05559</td>\n",
       "      <td>0.808964</td>\n",
       "      <td>0.106571</td>\n",
       "      <td>0.582141</td>\n",
       "      <td>0.031758</td>\n",
       "      <td>0.533650</td>\n",
       "      <td>0.088020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153146</th>\n",
       "      <td>fff7fc22a0cdccd3</td>\n",
       "      <td>0.811368</td>\n",
       "      <td>0.108637</td>\n",
       "      <td>0.586661</td>\n",
       "      <td>0.032187</td>\n",
       "      <td>0.537916</td>\n",
       "      <td>0.089140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153147</th>\n",
       "      <td>fff83b80284d8440</td>\n",
       "      <td>0.810573</td>\n",
       "      <td>0.107946</td>\n",
       "      <td>0.585162</td>\n",
       "      <td>0.032044</td>\n",
       "      <td>0.536500</td>\n",
       "      <td>0.088767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153148</th>\n",
       "      <td>fff8ef316d0c6990</td>\n",
       "      <td>0.812162</td>\n",
       "      <td>0.109327</td>\n",
       "      <td>0.588157</td>\n",
       "      <td>0.032330</td>\n",
       "      <td>0.539329</td>\n",
       "      <td>0.089513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153149</th>\n",
       "      <td>fff8f521a7dbcd47</td>\n",
       "      <td>0.812286</td>\n",
       "      <td>0.109436</td>\n",
       "      <td>0.588391</td>\n",
       "      <td>0.032352</td>\n",
       "      <td>0.539551</td>\n",
       "      <td>0.089572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153150</th>\n",
       "      <td>fff8f64043129fa2</td>\n",
       "      <td>0.812225</td>\n",
       "      <td>0.109382</td>\n",
       "      <td>0.588276</td>\n",
       "      <td>0.032341</td>\n",
       "      <td>0.539442</td>\n",
       "      <td>0.089543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153151</th>\n",
       "      <td>fff9d70fe0722906</td>\n",
       "      <td>0.811735</td>\n",
       "      <td>0.108955</td>\n",
       "      <td>0.587352</td>\n",
       "      <td>0.032253</td>\n",
       "      <td>0.538569</td>\n",
       "      <td>0.089312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153152</th>\n",
       "      <td>fff9fa508f400ee6</td>\n",
       "      <td>0.875197</td>\n",
       "      <td>0.170447</td>\n",
       "      <td>0.707008</td>\n",
       "      <td>0.042329</td>\n",
       "      <td>0.653104</td>\n",
       "      <td>0.119078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153153</th>\n",
       "      <td>fffa3fae1890b40a</td>\n",
       "      <td>0.812129</td>\n",
       "      <td>0.109299</td>\n",
       "      <td>0.588096</td>\n",
       "      <td>0.032324</td>\n",
       "      <td>0.539271</td>\n",
       "      <td>0.089498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153154</th>\n",
       "      <td>fffa8a11c4378854</td>\n",
       "      <td>0.802325</td>\n",
       "      <td>0.101146</td>\n",
       "      <td>0.569817</td>\n",
       "      <td>0.030625</td>\n",
       "      <td>0.522058</td>\n",
       "      <td>0.085048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153155</th>\n",
       "      <td>fffac2a094c8e0e2</td>\n",
       "      <td>0.809205</td>\n",
       "      <td>0.106772</td>\n",
       "      <td>0.582589</td>\n",
       "      <td>0.031800</td>\n",
       "      <td>0.534072</td>\n",
       "      <td>0.088129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153156</th>\n",
       "      <td>fffb5451268fb5ba</td>\n",
       "      <td>0.019951</td>\n",
       "      <td>0.000261</td>\n",
       "      <td>0.004689</td>\n",
       "      <td>0.000451</td>\n",
       "      <td>0.004116</td>\n",
       "      <td>0.001158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153157</th>\n",
       "      <td>fffc2b34bbe61c8d</td>\n",
       "      <td>0.774340</td>\n",
       "      <td>0.082438</td>\n",
       "      <td>0.520835</td>\n",
       "      <td>0.026591</td>\n",
       "      <td>0.475985</td>\n",
       "      <td>0.074261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153158</th>\n",
       "      <td>fffc489742ffe69b</td>\n",
       "      <td>0.019956</td>\n",
       "      <td>0.000262</td>\n",
       "      <td>0.004691</td>\n",
       "      <td>0.000451</td>\n",
       "      <td>0.004117</td>\n",
       "      <td>0.001159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153159</th>\n",
       "      <td>fffcd0960ee309b5</td>\n",
       "      <td>0.808995</td>\n",
       "      <td>0.106593</td>\n",
       "      <td>0.582196</td>\n",
       "      <td>0.031763</td>\n",
       "      <td>0.533700</td>\n",
       "      <td>0.088032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153160</th>\n",
       "      <td>fffd7a9a6eb32c16</td>\n",
       "      <td>0.878790</td>\n",
       "      <td>0.176799</td>\n",
       "      <td>0.715032</td>\n",
       "      <td>0.043479</td>\n",
       "      <td>0.661199</td>\n",
       "      <td>0.122093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153161</th>\n",
       "      <td>fffda9e8d6fafa9e</td>\n",
       "      <td>0.832712</td>\n",
       "      <td>0.121309</td>\n",
       "      <td>0.622009</td>\n",
       "      <td>0.033910</td>\n",
       "      <td>0.570520</td>\n",
       "      <td>0.095269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153162</th>\n",
       "      <td>fffe8f1340a79fc2</td>\n",
       "      <td>0.825328</td>\n",
       "      <td>0.116007</td>\n",
       "      <td>0.609015</td>\n",
       "      <td>0.033088</td>\n",
       "      <td>0.558371</td>\n",
       "      <td>0.092651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153163</th>\n",
       "      <td>ffffce3fb183ee80</td>\n",
       "      <td>0.810522</td>\n",
       "      <td>0.107901</td>\n",
       "      <td>0.585066</td>\n",
       "      <td>0.032034</td>\n",
       "      <td>0.536409</td>\n",
       "      <td>0.088742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id     toxic  severe_toxic   obscene    threat  \\\n",
       "153144  fff7159b3ee95618  0.866605  0.160197      0.690027  0.040850   \n",
       "153145  fff718ffe5f05559  0.808964  0.106571      0.582141  0.031758   \n",
       "153146  fff7fc22a0cdccd3  0.811368  0.108637      0.586661  0.032187   \n",
       "153147  fff83b80284d8440  0.810573  0.107946      0.585162  0.032044   \n",
       "153148  fff8ef316d0c6990  0.812162  0.109327      0.588157  0.032330   \n",
       "153149  fff8f521a7dbcd47  0.812286  0.109436      0.588391  0.032352   \n",
       "153150  fff8f64043129fa2  0.812225  0.109382      0.588276  0.032341   \n",
       "153151  fff9d70fe0722906  0.811735  0.108955      0.587352  0.032253   \n",
       "153152  fff9fa508f400ee6  0.875197  0.170447      0.707008  0.042329   \n",
       "153153  fffa3fae1890b40a  0.812129  0.109299      0.588096  0.032324   \n",
       "153154  fffa8a11c4378854  0.802325  0.101146      0.569817  0.030625   \n",
       "153155  fffac2a094c8e0e2  0.809205  0.106772      0.582589  0.031800   \n",
       "153156  fffb5451268fb5ba  0.019951  0.000261      0.004689  0.000451   \n",
       "153157  fffc2b34bbe61c8d  0.774340  0.082438      0.520835  0.026591   \n",
       "153158  fffc489742ffe69b  0.019956  0.000262      0.004691  0.000451   \n",
       "153159  fffcd0960ee309b5  0.808995  0.106593      0.582196  0.031763   \n",
       "153160  fffd7a9a6eb32c16  0.878790  0.176799      0.715032  0.043479   \n",
       "153161  fffda9e8d6fafa9e  0.832712  0.121309      0.622009  0.033910   \n",
       "153162  fffe8f1340a79fc2  0.825328  0.116007      0.609015  0.033088   \n",
       "153163  ffffce3fb183ee80  0.810522  0.107901      0.585066  0.032034   \n",
       "\n",
       "          insult  identity_hate  \n",
       "153144  0.636490  0.114437       \n",
       "153145  0.533650  0.088020       \n",
       "153146  0.537916  0.089140       \n",
       "153147  0.536500  0.088767       \n",
       "153148  0.539329  0.089513       \n",
       "153149  0.539551  0.089572       \n",
       "153150  0.539442  0.089543       \n",
       "153151  0.538569  0.089312       \n",
       "153152  0.653104  0.119078       \n",
       "153153  0.539271  0.089498       \n",
       "153154  0.522058  0.085048       \n",
       "153155  0.534072  0.088129       \n",
       "153156  0.004116  0.001158       \n",
       "153157  0.475985  0.074261       \n",
       "153158  0.004117  0.001159       \n",
       "153159  0.533700  0.088032       \n",
       "153160  0.661199  0.122093       \n",
       "153161  0.570520  0.095269       \n",
       "153162  0.558371  0.092651       \n",
       "153163  0.536409  0.088742       "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subm_df = pd.DataFrame(data=preds, columns=label_cols) # -- if \"none\" included\n",
    "# subm_df = pd.DataFrame(data=preds[:,:6], columns=label_cols) # -- if \"none\" included\n",
    "\n",
    "subm_df.insert(0, 'id', test.id)\n",
    "subm_df.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153164, 153164)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preds), len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm_df.to_csv(f'{PATH}/submission/multi-label-lstm-1.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "123px",
    "width": "251px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
